{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**Computational Social Science**\n",
    "\n",
    "*Assignment 1*\n",
    "\n",
    "Link to github: https://github.com/Dribo/02467_A_1\n",
    "\n",
    "*Contribution statement*\n",
    "\n",
    "All the exercises have been completed in cooperation, where we have worked to complete one assignment before moving on to the next."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Part 1: Using web-scraping to gather data**\n",
    "The following cells contain the code for solve part 1 of the exercise"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Imports\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philiphelsted/opt/anaconda3/envs/02467CSS/lib/python3.10/site-packages/urllib3/connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host '2019.ic2s2.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "requests.packages.urllib3.util.ssl_.DEFAULT_CIPHERS += 'HIGH:!DH:!aNULL'\n",
    "try:\n",
    "    requests.packages.urllib3.contrib.pyopenssl.DEFAULT_SSL_CIPHER_LIST += 'HIGH:!DH:!aNULL'\n",
    "except AttributeError:\n",
    "    # no pyopenssl support used / needed / available\n",
    "    pass\n",
    "\n",
    "# Getting the web-page\n",
    "link19oral = \"https://2019.ic2s2.org/oral-presentations/\"\n",
    "link19post = \"https://2019.ic2s2.org/posters/\"\n",
    "r = requests.get(link19oral, verify=False)\n",
    "soup = BeautifulSoup(r.content)\n",
    "div = soup.find(\"div\", {\"class\":\"col-md-8\"})\n",
    "ps = div.findAll('p')\n",
    "relevant = ps[3:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Creating regex for filtering out names on the web-page for oral presentations\n",
    "# regex1 is for names that have an initial in the middle, regex2 is for all other names\n",
    "regex1 = r\" ([a-zA-ZÀ-ÿ]* ([A-Z]. )+[a-zA-ZÀ-ÿ]+[.,])\"\n",
    "regex2 = r\" ([a-zA-ZÀ-ÿ]* [a-zA-ZÀ-ÿ]+[.,])\"\n",
    "names = []\n",
    "names1 = []\n",
    "# Here we loop through the relevant part of the web-page and use the RegEx to find all the names and add them to a list\n",
    "for r in relevant:\n",
    "    retrieved = re.findall(regex1, str(r), re.UNICODE)\n",
    "    names += retrieved\n",
    "\n",
    "# Remove trailing spaces/dots\n",
    "for i in range(len(names)):\n",
    "    names[i] = names[i][0][:-1]\n",
    "\n",
    "# This is the same but for regex2\n",
    "for r in relevant:\n",
    "    retrieved = re.findall(regex2, str(r), re.UNICODE)\n",
    "    names1 += retrieved\n",
    "\n",
    "for i in range(len(names1)):\n",
    "    names1[i] = names1[i][:-1]\n",
    "\n",
    "names += names1\n",
    "list_of_presenters = names"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philiphelsted/opt/anaconda3/envs/02467CSS/lib/python3.10/site-packages/urllib3/connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host '2019.ic2s2.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Getting the web-page for the posters\n",
    "r = requests.get(link19post, verify=False)\n",
    "soup = BeautifulSoup(r.content)\n",
    "uls = soup.findAll('ul')\n",
    "r1 = list(uls)[6]\n",
    "r2 = list(uls)[7]\n",
    "\n",
    "relevant1 = []\n",
    "relevant2 = []\n",
    "\n",
    "# Splitting the strings at new-lines\n",
    "for x in list(r1):\n",
    "    if x != '\\n':\n",
    "        relevant1.append(x)\n",
    "for x in list(r2):\n",
    "    if x != '\\n':\n",
    "        relevant2.append(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of presenters with dublicates: 742\n",
      "List of presnters without dublicates : 613\n"
     ]
    }
   ],
   "source": [
    "# Regex for filtering of posters\n",
    "regex1 = r\"<li>[a-zA-Z ]*<span>\"\n",
    "names = []\n",
    "names1 = []\n",
    "names2 = []\n",
    "names3 = []\n",
    "# The same as before where we use the regex to filter the strings and find the names\n",
    "for r in relevant1:\n",
    "    retrieved = re.findall(regex1, str(r), re.UNICODE)\n",
    "    names += retrieved\n",
    "\n",
    "for i in range(len(names)):\n",
    "    names[i] = names[i][4:-6]\n",
    "    names[i] = names[i].split(' and ')\n",
    "    for j in range(len(names[i])):\n",
    "        names1 += [names[i].pop(0)]\n",
    "\n",
    "for r in relevant2:\n",
    "    retrieved = re.findall(regex1, str(r), re.UNICODE)\n",
    "    names2 += retrieved\n",
    "\n",
    "for i in range(len(names2)):\n",
    "    names2[i] = names2[i][4:-6]\n",
    "    names2[i] = names2[i].split(' and ')\n",
    "    for j in range(len(names2[i])):\n",
    "        names3 += [names2[i].pop(0)]\n",
    "\n",
    "list_of_presenters += names1 + names3\n",
    "# Create the list of presenters and turn it into a set to remove dublicates\n",
    "print('List of presenters with dublicates:', len(list_of_presenters))\n",
    "print('List of presenters without dublicates :',  len(set(list_of_presenters)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Part 1*\n",
    "\n",
    "    2. We got 613 unique authors in 2019 for both posters and oral presentations\n",
    "\n",
    "    3. One decision that was taken during the web-scraping was to use RegEx to filter the out everything but the names. What this did was result in some oddities, where some elements got included that weren't names, and some names were cut off a bit too early, especially if they contained an intial as a middle name."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Part 2: Getting Data from the Semantic Scholar API**\n",
    "**2.1**\n",
    "The starting point of the exercise will be the AuthorID.csv dataset, which contains Author names and IDs for all years. Some Authors did not show up in search, whom we will omit in the exercise.\n",
    "\n",
    "Collaborators not included, first search result for each author name used to retrieve Author ID.\n",
    "\n",
    "**2.2**\n",
    "The exact code is all the following"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from time import sleep"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Number of authors is printed here**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2743 total unique authors with Author ID, after omitting 270 due to unsuccessful search\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "        Read Dataset, remove rows with no Author ID\n",
    "\"\"\"\n",
    "NO_SEARCH_RESULT_ID = \"No Search Result\"\n",
    "\n",
    "df_authorID = pd.read_csv('data/AuthorID.csv')\n",
    "len_before = len(df_authorID)\n",
    "\n",
    "df_authorID = df_authorID.fillna(NO_SEARCH_RESULT_ID)\n",
    "df_authorID = df_authorID.loc[df_authorID['ID'] != NO_SEARCH_RESULT_ID]\n",
    "len_after = len(df_authorID)\n",
    "\n",
    "print(f\"{len_after} total unique authors with Author ID, after omitting {len_before-len_after} due to unsuccessful search\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 28 batches of size 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 11%|█         | 3/28 [04:11<34:56, 83.86s/it]\n",
      "\n",
      "  4%|▎         | 1/28 [00:03<01:24,  3.14s/it]\u001B[A\n",
      "  7%|▋         | 2/28 [00:06<01:27,  3.38s/it]\u001B[A\n",
      " 11%|█         | 3/28 [00:09<01:22,  3.29s/it]\u001B[A\n",
      " 14%|█▍        | 4/28 [00:13<01:25,  3.55s/it]\u001B[A\n",
      " 18%|█▊        | 5/28 [00:18<01:33,  4.07s/it]\u001B[A\n",
      " 21%|██▏       | 6/28 [00:23<01:30,  4.12s/it]\u001B[A\n",
      " 25%|██▌       | 7/28 [00:26<01:19,  3.78s/it]\u001B[A\n",
      " 29%|██▊       | 8/28 [00:29<01:14,  3.72s/it]\u001B[A\n",
      " 32%|███▏      | 9/28 [00:33<01:12,  3.82s/it]\u001B[A\n",
      " 36%|███▌      | 10/28 [00:38<01:11,  3.98s/it]\u001B[A\n",
      " 39%|███▉      | 11/28 [01:20<04:29, 15.83s/it]\u001B[A\n",
      " 43%|████▎     | 12/28 [01:25<03:18, 12.39s/it]\u001B[A\n",
      " 46%|████▋     | 13/28 [01:28<02:25,  9.72s/it]\u001B[A\n",
      " 50%|█████     | 14/28 [01:32<01:51,  8.00s/it]\u001B[A\n",
      " 54%|█████▎    | 15/28 [01:36<01:24,  6.54s/it]\u001B[A\n",
      " 57%|█████▋    | 16/28 [01:40<01:10,  5.89s/it]\u001B[A\n",
      " 61%|██████    | 17/28 [01:44<01:00,  5.48s/it]\u001B[A\n",
      " 64%|██████▍   | 18/28 [01:54<01:08,  6.81s/it]\u001B[A\n",
      " 68%|██████▊   | 19/28 [01:59<00:54,  6.03s/it]\u001B[A\n",
      " 71%|███████▏  | 20/28 [02:04<00:45,  5.72s/it]\u001B[A\n",
      " 75%|███████▌  | 21/28 [02:07<00:35,  5.10s/it]\u001B[A\n",
      " 79%|███████▊  | 22/28 [02:11<00:28,  4.74s/it]\u001B[A\n",
      " 82%|████████▏ | 23/28 [02:15<00:21,  4.34s/it]\u001B[A\n",
      " 86%|████████▌ | 24/28 [02:18<00:16,  4.12s/it]\u001B[A\n",
      " 89%|████████▉ | 25/28 [02:20<00:10,  3.48s/it]\u001B[A\n",
      " 93%|█████████▎| 26/28 [02:51<00:23, 11.75s/it]\u001B[A\n",
      " 96%|█████████▋| 27/28 [02:54<00:09,  9.05s/it]\u001B[A\n",
      "100%|██████████| 28/28 [02:56<00:00,  6.30s/it]\u001B[A\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "        Splits Author IDs into batches of size n\n",
    "\"\"\"\n",
    "AuthorIDs = list(df_authorID['ID'])\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "Batch_AuthorIDs = []\n",
    "\n",
    "# This chunks function is taken from a page on stackoverflow\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Helper function to split array into batches\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "Batch_AuthorIDs = list(chunks(AuthorIDs, BATCH_SIZE))\n",
    "print(f\"Generated {len(Batch_AuthorIDs)} batches of size {BATCH_SIZE}\")\n",
    "\n",
    "\"\"\"\n",
    "        Gets data and creates a list of each output from the API calls\n",
    "\"\"\"\n",
    "def get_data_from_authorIds(author_id_batch, max_attempts=3, delay_seconds=0):\n",
    "    if max_attempts == 0:\n",
    "        print(\"Error: A batch reached max attempts and will not be used later\")\n",
    "        return []\n",
    "\n",
    "    BASE_URL = \"https://api.semanticscholar.org/\"\n",
    "    VERSION = \"graph/v1/\"\n",
    "    RESOURCE = \"author/batch\"\n",
    "\n",
    "    complete_url = BASE_URL+VERSION+RESOURCE\n",
    "\n",
    "    data = {\"ids\":list(author_id_batch)}\n",
    "    params = {\"fields\":\"name,aliases,citationCount,papers,papers.title,papers.abstract,papers.year,papers.s2FieldsOfStudy,papers.fieldsOfStudy,papers.citationCount,papers.externalIds,papers.authors\"}\n",
    "\n",
    "    response = requests.post(complete_url, json=data, params=params)\n",
    "    response = response.json()\n",
    "\n",
    "    if len(response) <= 1:\n",
    "        sleep(delay_seconds)\n",
    "        return get_data_from_authorIds(author_id_batch=author_id_batch, max_attempts=max_attempts-1, delay_seconds=delay_seconds)\n",
    "\n",
    "    return response\n",
    "\n",
    "list_response_data = [get_data_from_authorIds(batch, max_attempts=3, delay_seconds=0) for batch in tqdm(Batch_AuthorIDs)]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 out of 28 searches were successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:00<00:00, 1357.14it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "        Compiles the list of JSON objects (dictionaries) into a list of DataFrames, then concatenated into a single DataFrame\n",
    "\"\"\"\n",
    "clean = [response_data for response_data in list_response_data if len(response_data) > 1]\n",
    "print(len(clean), \"out of\", len(list_response_data), \"searches were successful\")\n",
    "\n",
    "df_list_API_data = [pd.DataFrame.from_dict(response_data) for response_data in tqdm(clean)]\n",
    "df_API_data = pd.concat(df_list_API_data, ignore_index=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "        Creates a new column 'fieldOfStudy' using a helper function, which returns field directly from the 'papers' data.\n",
    "\"\"\"\n",
    "def get_field_of_study(list_papers):\n",
    "    if len(list_papers) == 0:\n",
    "        return None\n",
    "    try:\n",
    "        dict_field_count = defaultdict(lambda: 0)\n",
    "        for paper in list_papers:\n",
    "            list_field = paper['fieldsOfStudy']\n",
    "            if not list_field is None:\n",
    "                for field in list_field:\n",
    "                    dict_field_count[field] = dict_field_count[field] + 1\n",
    "\n",
    "        return max(dict_field_count, key=dict_field_count.get)\n",
    "    except KeyError: # When list_papers not a list but empty type\n",
    "        return None\n",
    "    except ValueError: # When dict is empty\n",
    "        return None\n",
    "\n",
    "df_API_data['fieldOfStudy'] = df_API_data.apply(lambda x: get_field_of_study(x['papers']), axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "        Finally, the Author Dataset is created by taking the required columns from API_data\n",
    "\"\"\"\n",
    "df_author_dataset = df_API_data[['authorId', 'name', 'aliases', 'citationCount', 'fieldOfStudy']].copy()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "        1. All paper data is taken from API_data, giving a list of JSON objects (dictionaries)\n",
    "        2. Converted to list of DataFrame\n",
    "        3. Concatenated\n",
    "\"\"\"\n",
    "list_paper_data = list(df_API_data['papers'])\n",
    "\n",
    "df_list_Paper_data = [pd.DataFrame.from_dict(paper_data) for paper_data in list_paper_data]\n",
    "df_Paper_data = pd.concat(df_list_Paper_data, ignore_index=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "        Extra columns required for papers are added into full Paper_data dataset.\n",
    "        Then the dataset is split into Final_Paper, and Abstract datasets\n",
    "\"\"\"\n",
    "def get_DOI_Id(externalIds):\n",
    "    try:\n",
    "        return externalIds['DOI']\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "def get_Author_Ids(authors):\n",
    "    IDs = []\n",
    "    try:\n",
    "        for author in authors:\n",
    "            ID = author['authorId']\n",
    "            if ID not in IDs:\n",
    "                IDs += [ID]\n",
    "        if len(IDs) == 0:\n",
    "            return None\n",
    "        return IDs\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "def get_fields_of_study(s2FieldsOfStudy):\n",
    "    list_fields = []\n",
    "    for dict_study in s2FieldsOfStudy:\n",
    "        field = dict_study['category']\n",
    "        if field not in list_fields:\n",
    "            list_fields.append(field)\n",
    "    return list_fields if list_fields else None\n",
    "\n",
    "df_Paper_data['externalId.DOI'] = df_Paper_data.apply(lambda x: get_DOI_Id(x['externalIds']), axis=1)\n",
    "df_Paper_data['authorIds'] = df_Paper_data.apply(lambda x: get_Author_Ids(x['authors']), axis=1)\n",
    "df_Paper_data['fields'] = df_Paper_data.apply(lambda x: get_fields_of_study(x['s2FieldsOfStudy']), axis=1)\n",
    "\n",
    "# Datasets 2 and 3 are created\n",
    "df_Final_Paper_data = df_Paper_data[['paperId', 'title', 'year', 'externalId.DOI', 'citationCount', 'fields', 'authorIds']].copy()\n",
    "df_Paper_Abstract_data = df_Paper_data[['paperId', 'abstract']].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**2.3: Final lengths of DataFrames**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final length of author data:\n",
      "2643\n",
      "Final length of paper data:\n",
      "96060\n"
     ]
    }
   ],
   "source": [
    "print(\"Final length of author data:\",\n",
    "      len(df_author_dataset),\n",
    "      \"Final length of paper data:\",\n",
    "      len(df_Final_Paper_data), sep='\\n'\n",
    "      )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Cells for looking at datasets**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "        authorId                name  \\\n0     2081923667          Ding Jieyu   \n1       47632726           Qiusi Sun   \n2       47132201       Zhang Jingwen   \n3        1818176  Mahmoudreza Babaei   \n4        2709512    Juhi Kulshrestha   \n...          ...                 ...   \n2638  2074453526         Nak Won Rim   \n2639     3130159           M. Berman   \n2640     4937157         Y. C. Leong   \n2641     8912718       K. de la Haye   \n2642     3937517        Abigail Horn   \n\n                                                aliases  citationCount  \\\n0                                          [Ding Jieyu]              0   \n1                                                  None             85   \n2                         [Zhan Jingwen, Zhang Jingwen]             46   \n3                                      [Mahmoud Babaei]            537   \n4                                                  None            718   \n...                                                 ...            ...   \n2638                                               None             27   \n2639  [Marc Glenn Berman, M. G. Berman, Marc G Berma...          10296   \n2640                     [Y.c. Leong, Yuan Chang Leong]           1229   \n2641    [K De La Haye, K. De La Haye, Kayla De La Haye]           1406   \n2642                  [Abigail E Horn, Abigail E. Horn]             49   \n\n           fieldOfStudy  \n0                  None  \n1      Computer Science  \n2     Materials Science  \n3      Computer Science  \n4      Computer Science  \n...                 ...  \n2638           Medicine  \n2639           Medicine  \n2640         Psychology  \n2641           Medicine  \n2642            Biology  \n\n[2643 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>authorId</th>\n      <th>name</th>\n      <th>aliases</th>\n      <th>citationCount</th>\n      <th>fieldOfStudy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2081923667</td>\n      <td>Ding Jieyu</td>\n      <td>[Ding Jieyu]</td>\n      <td>0</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>47632726</td>\n      <td>Qiusi Sun</td>\n      <td>None</td>\n      <td>85</td>\n      <td>Computer Science</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>47132201</td>\n      <td>Zhang Jingwen</td>\n      <td>[Zhan Jingwen, Zhang Jingwen]</td>\n      <td>46</td>\n      <td>Materials Science</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1818176</td>\n      <td>Mahmoudreza Babaei</td>\n      <td>[Mahmoud Babaei]</td>\n      <td>537</td>\n      <td>Computer Science</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2709512</td>\n      <td>Juhi Kulshrestha</td>\n      <td>None</td>\n      <td>718</td>\n      <td>Computer Science</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2638</th>\n      <td>2074453526</td>\n      <td>Nak Won Rim</td>\n      <td>None</td>\n      <td>27</td>\n      <td>Medicine</td>\n    </tr>\n    <tr>\n      <th>2639</th>\n      <td>3130159</td>\n      <td>M. Berman</td>\n      <td>[Marc Glenn Berman, M. G. Berman, Marc G Berma...</td>\n      <td>10296</td>\n      <td>Medicine</td>\n    </tr>\n    <tr>\n      <th>2640</th>\n      <td>4937157</td>\n      <td>Y. C. Leong</td>\n      <td>[Y.c. Leong, Yuan Chang Leong]</td>\n      <td>1229</td>\n      <td>Psychology</td>\n    </tr>\n    <tr>\n      <th>2641</th>\n      <td>8912718</td>\n      <td>K. de la Haye</td>\n      <td>[K De La Haye, K. De La Haye, Kayla De La Haye]</td>\n      <td>1406</td>\n      <td>Medicine</td>\n    </tr>\n    <tr>\n      <th>2642</th>\n      <td>3937517</td>\n      <td>Abigail Horn</td>\n      <td>[Abigail E Horn, Abigail E. Horn]</td>\n      <td>49</td>\n      <td>Biology</td>\n    </tr>\n  </tbody>\n</table>\n<p>2643 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_author_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "                                        paperId  \\\n0      64b569cd286d2d868370923146a309875b7b7f02   \n1      917f3f0a34a7dc9a7602ba8c78932bbb9b3e6a42   \n2      1e16ff1601d724962171031493830e0599fd228e   \n3      288f55879cc77a1317aba73a51651405c7c69d24   \n4      a6d03cae8803bc9735f77765707a3fe570c3922e   \n...                                         ...   \n96055  319279136b0d07909dc1a66ed853f624c518371c   \n96056  669b985318857828b252664fb5027bf1ec3525a2   \n96057  babc51dd3a48cd077e86b3cce227cc3de541849a   \n96058  bfd319f19f29e78a36e6523a2f5e783179264626   \n96059  ebd10799af71dbbf8ab80e4c04d86fe640f49107   \n\n                                                   title  year  \\\n0                                 多刚体系统动力学方向矢量模型及多步块数值方法  2020   \n1                                   多体系统动力学微分-代数方程L-稳定方法  2019   \n2      Who would respond to A troll? A social network...  2021   \n3      Over-Time Trends in Incivility on Social Media...  2021   \n4      How do we make the virtual world a better plac...  2021   \n...                                                  ...   ...   \n96055   The HMGB1 C-Terminal Tail Regulates DNA Bending.  2016   \n96056  Single molecule microscopy reveals mechanistic...  2016   \n96057  Evaluating the Relationship between FRET Chang...  2016   \n96058  Single molecule studies of RNA polymerase II t...  2014   \n96059  Single molecule studies of RNA polymerase II t...  2014   \n\n                    externalId.DOI  citationCount  \\\n0        10.21656/1000-0887.400340              0   \n1        10.21656/1000-0887.400038              0   \n2        10.1016/J.CHB.2021.106786              5   \n3         10.3389/fpos.2021.741605              3   \n4       10.1016/j.tele.2021.101747              6   \n...                            ...            ...   \n96055    10.1016/j.jmb.2016.08.018             22   \n96056           10.1093/nar/gkw321             17   \n96057  10.1021/ACS.JCHEMED.5B00440              7   \n96058                         None              0   \n96059           10.4161/trns.27608              3   \n\n                               fields  \\\n0                       [Engineering]   \n1                           [Physics]   \n2      [Computer Science, Psychology]   \n3                         [Sociology]   \n4      [Computer Science, Psychology]   \n...                               ...   \n96055  [Medicine, Biology, Chemistry]   \n96056             [Medicine, Biology]   \n96057            [Chemistry, Biology]   \n96058             [Medicine, Biology]   \n96059             [Biology, Medicine]   \n\n                                               authorIds  \n0                     [2138901195, 46269805, 2081923667]  \n1         [1573538979, 1491245320, 2081923667, 50587356]  \n2                                   [47632726, 39003910]  \n3                         [47632726, 2496439, 102536922]  \n4                       [2056326856, 47632726, 30904401]  \n...                                                  ...  \n96055  [33905657, 3937517, 13278004, 50260726, 245772...  \n96056                        [3937517, 5909882, 2457729]  \n96057             [13278004, 3937517, 50260726, 5909882]  \n96058                        [3937517, 2457729, 5909882]  \n96059                        [3937517, 2457729, 5909882]  \n\n[96060 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>paperId</th>\n      <th>title</th>\n      <th>year</th>\n      <th>externalId.DOI</th>\n      <th>citationCount</th>\n      <th>fields</th>\n      <th>authorIds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>64b569cd286d2d868370923146a309875b7b7f02</td>\n      <td>多刚体系统动力学方向矢量模型及多步块数值方法</td>\n      <td>2020</td>\n      <td>10.21656/1000-0887.400340</td>\n      <td>0</td>\n      <td>[Engineering]</td>\n      <td>[2138901195, 46269805, 2081923667]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>917f3f0a34a7dc9a7602ba8c78932bbb9b3e6a42</td>\n      <td>多体系统动力学微分-代数方程L-稳定方法</td>\n      <td>2019</td>\n      <td>10.21656/1000-0887.400038</td>\n      <td>0</td>\n      <td>[Physics]</td>\n      <td>[1573538979, 1491245320, 2081923667, 50587356]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1e16ff1601d724962171031493830e0599fd228e</td>\n      <td>Who would respond to A troll? A social network...</td>\n      <td>2021</td>\n      <td>10.1016/J.CHB.2021.106786</td>\n      <td>5</td>\n      <td>[Computer Science, Psychology]</td>\n      <td>[47632726, 39003910]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>288f55879cc77a1317aba73a51651405c7c69d24</td>\n      <td>Over-Time Trends in Incivility on Social Media...</td>\n      <td>2021</td>\n      <td>10.3389/fpos.2021.741605</td>\n      <td>3</td>\n      <td>[Sociology]</td>\n      <td>[47632726, 2496439, 102536922]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>a6d03cae8803bc9735f77765707a3fe570c3922e</td>\n      <td>How do we make the virtual world a better plac...</td>\n      <td>2021</td>\n      <td>10.1016/j.tele.2021.101747</td>\n      <td>6</td>\n      <td>[Computer Science, Psychology]</td>\n      <td>[2056326856, 47632726, 30904401]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>96055</th>\n      <td>319279136b0d07909dc1a66ed853f624c518371c</td>\n      <td>The HMGB1 C-Terminal Tail Regulates DNA Bending.</td>\n      <td>2016</td>\n      <td>10.1016/j.jmb.2016.08.018</td>\n      <td>22</td>\n      <td>[Medicine, Biology, Chemistry]</td>\n      <td>[33905657, 3937517, 13278004, 50260726, 245772...</td>\n    </tr>\n    <tr>\n      <th>96056</th>\n      <td>669b985318857828b252664fb5027bf1ec3525a2</td>\n      <td>Single molecule microscopy reveals mechanistic...</td>\n      <td>2016</td>\n      <td>10.1093/nar/gkw321</td>\n      <td>17</td>\n      <td>[Medicine, Biology]</td>\n      <td>[3937517, 5909882, 2457729]</td>\n    </tr>\n    <tr>\n      <th>96057</th>\n      <td>babc51dd3a48cd077e86b3cce227cc3de541849a</td>\n      <td>Evaluating the Relationship between FRET Chang...</td>\n      <td>2016</td>\n      <td>10.1021/ACS.JCHEMED.5B00440</td>\n      <td>7</td>\n      <td>[Chemistry, Biology]</td>\n      <td>[13278004, 3937517, 50260726, 5909882]</td>\n    </tr>\n    <tr>\n      <th>96058</th>\n      <td>bfd319f19f29e78a36e6523a2f5e783179264626</td>\n      <td>Single molecule studies of RNA polymerase II t...</td>\n      <td>2014</td>\n      <td>None</td>\n      <td>0</td>\n      <td>[Medicine, Biology]</td>\n      <td>[3937517, 2457729, 5909882]</td>\n    </tr>\n    <tr>\n      <th>96059</th>\n      <td>ebd10799af71dbbf8ab80e4c04d86fe640f49107</td>\n      <td>Single molecule studies of RNA polymerase II t...</td>\n      <td>2014</td>\n      <td>10.4161/trns.27608</td>\n      <td>3</td>\n      <td>[Biology, Medicine]</td>\n      <td>[3937517, 2457729, 5909882]</td>\n    </tr>\n  </tbody>\n</table>\n<p>96060 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Final_Paper_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "                                        paperId  \\\n0      64b569cd286d2d868370923146a309875b7b7f02   \n1      917f3f0a34a7dc9a7602ba8c78932bbb9b3e6a42   \n2      1e16ff1601d724962171031493830e0599fd228e   \n3      288f55879cc77a1317aba73a51651405c7c69d24   \n4      a6d03cae8803bc9735f77765707a3fe570c3922e   \n...                                         ...   \n96055  319279136b0d07909dc1a66ed853f624c518371c   \n96056  669b985318857828b252664fb5027bf1ec3525a2   \n96057  babc51dd3a48cd077e86b3cce227cc3de541849a   \n96058  bfd319f19f29e78a36e6523a2f5e783179264626   \n96059  ebd10799af71dbbf8ab80e4c04d86fe640f49107   \n\n                                                abstract  \n0                                                   None  \n1                                                   None  \n2                                                   None  \n3      Incivility in social media has become a major ...  \n4                                                   None  \n...                                                  ...  \n96055                                               None  \n96056  Transcription by RNA polymerase II (Pol II) is...  \n96057  FRET (Forster resonance energy transfer) invol...  \n96058  Eukaryotic mRNA transcription by RNA polymeras...  \n96059  Eukaryotic mRNA transcription by RNA polymeras...  \n\n[96060 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>paperId</th>\n      <th>abstract</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>64b569cd286d2d868370923146a309875b7b7f02</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>917f3f0a34a7dc9a7602ba8c78932bbb9b3e6a42</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1e16ff1601d724962171031493830e0599fd228e</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>288f55879cc77a1317aba73a51651405c7c69d24</td>\n      <td>Incivility in social media has become a major ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>a6d03cae8803bc9735f77765707a3fe570c3922e</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>96055</th>\n      <td>319279136b0d07909dc1a66ed853f624c518371c</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>96056</th>\n      <td>669b985318857828b252664fb5027bf1ec3525a2</td>\n      <td>Transcription by RNA polymerase II (Pol II) is...</td>\n    </tr>\n    <tr>\n      <th>96057</th>\n      <td>babc51dd3a48cd077e86b3cce227cc3de541849a</td>\n      <td>FRET (Forster resonance energy transfer) invol...</td>\n    </tr>\n    <tr>\n      <th>96058</th>\n      <td>bfd319f19f29e78a36e6523a2f5e783179264626</td>\n      <td>Eukaryotic mRNA transcription by RNA polymeras...</td>\n    </tr>\n    <tr>\n      <th>96059</th>\n      <td>ebd10799af71dbbf8ab80e4c04d86fe640f49107</td>\n      <td>Eukaryotic mRNA transcription by RNA polymeras...</td>\n    </tr>\n  </tbody>\n</table>\n<p>96060 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Paper_Abstract_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Part 3: Law of large numbers**\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Part 1: Using web-scraping to gather data**\n",
    "The following cells contain the code for solve part 1 of the exercise"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\anaconda3\\envs\\02467 - css\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host '2019.ic2s2.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "requests.packages.urllib3.util.ssl_.DEFAULT_CIPHERS += 'HIGH:!DH:!aNULL'\n",
    "try:\n",
    "    requests.packages.urllib3.contrib.pyopenssl.DEFAULT_SSL_CIPHER_LIST += 'HIGH:!DH:!aNULL'\n",
    "except AttributeError:\n",
    "    # no pyopenssl support used / needed / available\n",
    "    pass\n",
    "\n",
    "# Getting the web-page\n",
    "link19oral = \"https://2019.ic2s2.org/oral-presentations/\"\n",
    "link19post = \"https://2019.ic2s2.org/posters/\"\n",
    "r = requests.get(link19oral, verify=False)\n",
    "soup = BeautifulSoup(r.content)\n",
    "div = soup.find(\"div\", {\"class\":\"col-md-8\"})\n",
    "ps = div.findAll('p')\n",
    "relevant = ps[3:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Creating regex for filtering out names on the web-page for oral presentations\n",
    "# regex1 is for names that have an initial in the middle, regex2 is for all other names\n",
    "regex1 = r\" ([a-zA-ZÀ-ÿ]* ([A-Z]. )+[a-zA-ZÀ-ÿ]+[.,])\"\n",
    "regex2 = r\" ([a-zA-ZÀ-ÿ]* [a-zA-ZÀ-ÿ]+[.,])\"\n",
    "names = []\n",
    "names1 = []\n",
    "# Here we loop through the relevant part of the web-page and use the RegEx to find all the names and add them to a list\n",
    "for r in relevant:\n",
    "    retrieved = re.findall(regex1, str(r), re.UNICODE)\n",
    "    names += retrieved\n",
    "\n",
    "# Remove trailing spaces/dots\n",
    "for i in range(len(names)):\n",
    "    names[i] = names[i][0][:-1]\n",
    "\n",
    "# This is the same but for regex2\n",
    "for r in relevant:\n",
    "    retrieved = re.findall(regex2, str(r), re.UNICODE)\n",
    "    names1 += retrieved\n",
    "\n",
    "for i in range(len(names1)):\n",
    "    names1[i] = names1[i][:-1]\n",
    "\n",
    "names += names1\n",
    "list_of_presenters = names"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\anaconda3\\envs\\02467 - css\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host '2019.ic2s2.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Getting the web-page for the posters\n",
    "r = requests.get(link19post, verify=False)\n",
    "soup = BeautifulSoup(r.content)\n",
    "uls = soup.findAll('ul')\n",
    "r1 = list(uls)[6]\n",
    "r2 = list(uls)[7]\n",
    "\n",
    "relevant1 = []\n",
    "relevant2 = []\n",
    "\n",
    "# Splitting the strings at new-lines\n",
    "for x in list(r1):\n",
    "    if x != '\\n':\n",
    "        relevant1.append(x)\n",
    "for x in list(r2):\n",
    "    if x != '\\n':\n",
    "        relevant2.append(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of presenters with dublicates: 742\n",
      "List of presnters without dublicates : 613\n"
     ]
    }
   ],
   "source": [
    "# Regex for filtering of posters\n",
    "regex1 = r\"<li>[a-zA-Z ]*<span>\"\n",
    "names = []\n",
    "names1 = []\n",
    "names2 = []\n",
    "names3 = []\n",
    "# The same as before where we use the regex to filter the strings and find the names\n",
    "for r in relevant1:\n",
    "    retrieved = re.findall(regex1, str(r), re.UNICODE)\n",
    "    names += retrieved\n",
    "\n",
    "for i in range(len(names)):\n",
    "    names[i] = names[i][4:-6]\n",
    "    names[i] = names[i].split(' and ')\n",
    "    for j in range(len(names[i])):\n",
    "        names1 += [names[i].pop(0)]\n",
    "\n",
    "for r in relevant2:\n",
    "    retrieved = re.findall(regex1, str(r), re.UNICODE)\n",
    "    names2 += retrieved\n",
    "\n",
    "for i in range(len(names2)):\n",
    "    names2[i] = names2[i][4:-6]\n",
    "    names2[i] = names2[i].split(' and ')\n",
    "    for j in range(len(names2[i])):\n",
    "        names3 += [names2[i].pop(0)]\n",
    "\n",
    "list_of_presenters += names1 + names3\n",
    "# Create the list of presenters and turn it into a set to remove dublicates\n",
    "print('List of presenters with dublicates:', len(list_of_presenters))\n",
    "print('List of presnters without dublicates :',  len(set(list_of_presenters)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Part 1*\n",
    "\n",
    "    2. We got 613 unique authors in 2019 for both posters and oral presentations\n",
    "\n",
    "    3. One decision that was taken during the web-scraping was to use RegEx to filter the out everything but the names. What this did was result in some oddities, where some elements got included that weren't names, and some names were cut off a bit too early, especially if they contained an intial as a middle name."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}